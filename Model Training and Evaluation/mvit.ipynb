{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24158d78",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, f1_score, roc_auc_score\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "from collections import Counter\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d1068a",
   "metadata": {},
   "source": [
    "# Set Seeds for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0efb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Python random\n",
    "random.seed(SEED)\n",
    "\n",
    "# Numpy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)  # if using multi-GPU\n",
    "\n",
    "# PyTorch backend\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"Seeds set to {SEED} for reproducibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c5b06",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893324e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations - Minimal transformations without data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # RGB normalization\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # RGB normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c8686",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "class BladderTissueDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, label_encoder=None, fit_label_encoder=False, imaging_type_encoder=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (DataFrame): DataFrame with HLY (image paths) and tissue type (labels) columns.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            label_encoder (LabelEncoder, optional): Pre-fitted label encoder. If None, creates new one.\n",
    "            fit_label_encoder (bool): Whether to fit the label encoder on this dataset's labels.\n",
    "            imaging_type_encoder (LabelEncoder, optional): Pre-fitted imaging type encoder.\n",
    "        \"\"\"\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "        if label_encoder is None:\n",
    "            self.label_encoder = LabelEncoder()\n",
    "            if fit_label_encoder:\n",
    "                self.labels = self.label_encoder.fit_transform(self.data['tissue type'])\n",
    "            else:\n",
    "                raise ValueError(\"Must provide label_encoder or set fit_label_encoder=True\")\n",
    "        else:\n",
    "            self.label_encoder = label_encoder\n",
    "            self.labels = self.label_encoder.transform(self.data['tissue type'])\n",
    "        \n",
    "        # Handle imaging type encoding\n",
    "        if imaging_type_encoder is None:\n",
    "            self.imaging_type_encoder = LabelEncoder()\n",
    "            if fit_label_encoder:  # Use same flag as label encoder for consistency\n",
    "                self.imaging_types = self.imaging_type_encoder.fit_transform(self.data['imaging type'])\n",
    "            else:\n",
    "                raise ValueError(\"Must provide imaging_type_encoder or set fit_label_encoder=True\")\n",
    "        else:\n",
    "            self.imaging_type_encoder = imaging_type_encoder\n",
    "            self.imaging_types = self.imaging_type_encoder.transform(self.data['imaging type'])\n",
    "        \n",
    "        self.image_paths = self.data['HLY'].tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image: {img_path}\")\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        imaging_type = self.imaging_types[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.long), torch.tensor(imaging_type, dtype=torch.long)\n",
    "    \n",
    "    def get_label_encoder(self):\n",
    "        \"\"\"Return the label encoder for use with other datasets\"\"\"\n",
    "        return self.label_encoder\n",
    "    \n",
    "    def get_imaging_type_encoder(self):\n",
    "        \"\"\"Return the imaging type encoder for use with other datasets\"\"\"\n",
    "        return self.imaging_type_encoder\n",
    "    \n",
    "    def get_class_names(self):\n",
    "        \"\"\"Return the original class names\"\"\"\n",
    "        return self.label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffccb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets from DataFrames\n",
    "def create_datasets_from_dataframes(train_df, val_df, test_df):\n",
    "    \"\"\"\n",
    "    Create train, validation, and test datasets with proper label encoding\n",
    "    \"\"\"\n",
    "    # Create training dataset and fit label encoder\n",
    "    train_dataset = BladderTissueDataset(\n",
    "        dataframe=train_df, \n",
    "        transform=train_transform,\n",
    "        fit_label_encoder=True  \n",
    "    )\n",
    "    \n",
    "    # Get the fitted label encoder\n",
    "    le = train_dataset.get_label_encoder()\n",
    "    \n",
    "    # Get the fitted imaging type encoder\n",
    "    imaging_type_encoder = train_dataset.get_imaging_type_encoder()\n",
    "    \n",
    "    # Create validation dataset using the same label encoder\n",
    "    val_dataset = BladderTissueDataset(\n",
    "        dataframe=val_df,\n",
    "        transform=val_test_transform,\n",
    "        label_encoder=le,\n",
    "        imaging_type_encoder=imaging_type_encoder\n",
    "    )\n",
    "    \n",
    "    # Create test dataset using the same label encoder\n",
    "    test_dataset = BladderTissueDataset(\n",
    "        dataframe=test_df,\n",
    "        transform=val_test_transform,\n",
    "        label_encoder=le,\n",
    "        imaging_type_encoder=imaging_type_encoder\n",
    "    )\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset, le, imaging_type_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa395bf",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fab392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "def create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
    "    \"\"\"\n",
    "    Create dataloaders for training, validation, and testing\n",
    "    \"\"\"\n",
    "    # Worker seed for reproducibility\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "    \n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(42)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=seed_worker,    \n",
    "        generator=g    \n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        pin_memory=True,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/ebt-dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/ebt-dataset/test.csv\")\n",
    "valid_df = pd.read_csv(\"/kaggle/input/ebt-dataset/valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36cd6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset, label_encoder, imaging_type_encoder = create_datasets_from_dataframes(\n",
    "    train_df, valid_df, test_df\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_dataset, val_dataset, test_dataset, \n",
    "    batch_size=32, \n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b11e0",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45616f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(train_loader, num_classes):\n",
    "    \"\"\"Compute class weights for handling imbalanced datasets\"\"\"\n",
    "    class_counts = Counter()\n",
    "\n",
    "    for _, labels, _ in train_loader:\n",
    "        class_counts.update(labels.numpy())\n",
    "\n",
    "    total_samples = sum(class_counts.values())\n",
    "\n",
    "    weights = []\n",
    "    for i in range(num_classes):\n",
    "        weights.append(total_samples / (num_classes * class_counts[i]))\n",
    "\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d12dc36",
   "metadata": {},
   "source": [
    "# Model Training Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        \n",
    "        # Training history\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "        \n",
    "    def train_model(self, num_epochs=25, lr=0.001, weight_decay=1e-4, save_best=True, model_name=\"model\"):\n",
    "        \"\"\"Train the model with early stopping and best model saving based on macro-F1\"\"\"\n",
    "        \n",
    "        # Loss function and optimizer\n",
    "        class_weights = compute_class_weights(self.train_loader, num_classes=len(self.train_loader.dataset.get_label_encoder().classes_))\n",
    "        class_weights = class_weights.to(self.device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "        \n",
    "        # Best model tracking\n",
    "        best_val_f1 = 0.0\n",
    "        best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "        patience = 5\n",
    "        patience_counter = 0\n",
    "        \n",
    "        print(f\"Starting training for {num_epochs} epochs...\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "            print('-' * 10)\n",
    "            \n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    self.model.train()\n",
    "                    dataloader = self.train_loader\n",
    "                else:\n",
    "                    self.model.eval()\n",
    "                    dataloader = self.val_loader\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                total_samples = 0\n",
    "                all_preds = []\n",
    "                all_labels = []\n",
    "                \n",
    "                # Progress bar\n",
    "                pbar = tqdm(dataloader, desc=f'{phase.capitalize()} ')\n",
    "                \n",
    "                for inputs, labels, imaging_types in pbar:\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "                    imaging_types = imaging_types.to(self.device)\n",
    "                    \n",
    "                    # Zero gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = self.model(inputs, imaging_types)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                        # Backward pass (only in training)\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    \n",
    "                    # Statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                    total_samples += inputs.size(0)\n",
    "                    \n",
    "                    # Store predictions and labels for F1 calculation\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    current_acc = running_corrects.double() / total_samples\n",
    "                    pbar.set_postfix({\n",
    "                        'Loss': f'{running_loss/total_samples:.4f}',\n",
    "                        'Acc': f'{current_acc:.4f}'\n",
    "                    })\n",
    "                \n",
    "                # Calculate epoch metrics\n",
    "                epoch_loss = running_loss / total_samples\n",
    "                epoch_acc = running_corrects.double() / total_samples\n",
    "                epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                \n",
    "                print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Macro-F1: {epoch_f1:.4f}')\n",
    "                \n",
    "                # Store metrics\n",
    "                if phase == 'train':\n",
    "                    self.train_losses.append(epoch_loss)\n",
    "                    self.train_accuracies.append(epoch_acc.cpu())\n",
    "                else:\n",
    "                    self.val_losses.append(epoch_loss)\n",
    "                    self.val_accuracies.append(epoch_acc.cpu())\n",
    "                \n",
    "                # Save best model based on validation macro-F1\n",
    "                if phase == 'val' and epoch_f1 > best_val_f1:\n",
    "                    best_val_f1 = epoch_f1\n",
    "                    best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "                    patience_counter = 0\n",
    "                    if save_best:\n",
    "                        torch.save(self.model.state_dict(), f'best_{model_name}.pth')\n",
    "                        print(f'âœ“ New best model saved with validation macro-F1: {best_val_f1:.4f}')\n",
    "                elif phase == 'val':\n",
    "                    patience_counter += 1\n",
    "            \n",
    "            # Learning rate scheduler step (after both train and val phases)\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "                break\n",
    "                \n",
    "            print()\n",
    "        \n",
    "        # Training complete\n",
    "        time_elapsed = time.time() - start_time\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best validation macro-F1: {best_val_f1:.4f}')\n",
    "        \n",
    "        # Load best model weights\n",
    "        self.model.load_state_dict(best_model_wts)\n",
    "        return self.model\n",
    "    \n",
    "    def evaluate_model(self, test_loader=None, class_names=['HGC', 'LGC', 'NST', 'NTL']):\n",
    "        \"\"\"Evaluate model on test set and return all metrics\"\"\"\n",
    "        if test_loader is None:\n",
    "            test_loader = self.test_loader\n",
    "            \n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        print(\"Evaluating on test set...\")\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels, imaging_types in tqdm(test_loader):\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                imaging_types = imaging_types.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs, imaging_types)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                # Store for detailed metrics\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        test_acc = 100 * correct / total\n",
    "        avg_test_loss = test_loss / total\n",
    "        \n",
    "        print(f'Test Accuracy: {test_acc:.2f}%')\n",
    "        print(f'Test Loss: {avg_test_loss:.4f}')\n",
    "        \n",
    "        # Detailed classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "        print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        print(f\"\\nConfusion Matrix:\")\n",
    "        print(cm)\n",
    "        \n",
    "        # Compute ROC-AUC scores\n",
    "        labels_bin = label_binarize(all_labels, classes=list(range(len(class_names))))\n",
    "        probs_array = np.array(all_probs)\n",
    "        \n",
    "        # Per-class ROC-AUC\n",
    "        per_class_auc = {}\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            try:\n",
    "                per_class_auc[class_name] = roc_auc_score(labels_bin[:, i], probs_array[:, i])\n",
    "            except:\n",
    "                per_class_auc[class_name] = 0.0\n",
    "        \n",
    "        # Macro ROC-AUC (average of per-class AUCs)\n",
    "        macro_auc = np.mean(list(per_class_auc.values()))\n",
    "        \n",
    "        # Micro ROC-AUC (using all predictions)\n",
    "        try:\n",
    "            micro_auc = roc_auc_score(labels_bin.ravel(), probs_array.ravel())\n",
    "        except:\n",
    "            micro_auc = 0.0\n",
    "        \n",
    "        print(f\"\\nROC-AUC Scores:\")\n",
    "        print(f\"Macro-average AUC: {macro_auc:.4f}\")\n",
    "        print(f\"Micro-average AUC: {micro_auc:.4f}\")\n",
    "        for class_name, auc_score in per_class_auc.items():\n",
    "            print(f\"{class_name} AUC: {auc_score:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'accuracy': test_acc,\n",
    "            'loss': avg_test_loss,\n",
    "            'predictions': all_preds,\n",
    "            'labels': all_labels,\n",
    "            'probabilities': all_probs,\n",
    "            'confusion_matrix': cm,\n",
    "            'classification_report': report,\n",
    "            'per_class_auc': per_class_auc,\n",
    "            'macro_auc': macro_auc,\n",
    "            'micro_auc': micro_auc\n",
    "        }\n",
    "    \n",
    "    def plot_training_history(self, save_path=None):\n",
    "        \"\"\"Plot training and validation metrics\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Plot losses\n",
    "        ax1.plot(self.train_losses, label='Train Loss', marker='o')\n",
    "        ax1.plot(self.val_losses, label='Validation Loss', marker='s')\n",
    "        ax1.set_title('Model Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Plot accuracies\n",
    "        ax2.plot(self.train_accuracies, label='Train Accuracy', marker='o')\n",
    "        ax2.plot(self.val_accuracies, label='Validation Accuracy', marker='s')\n",
    "        ax2.set_title('Model Accuracy')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071fa984",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a329e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MViTWithImagingType(nn.Module):\n",
    "    \"\"\"Wrapper class that adds imaging type embedding to MViT\"\"\"\n",
    "    def __init__(self, base_model, num_features, num_classes=4, num_imaging_types=2, embedding_dim=16):\n",
    "        super(MViTWithImagingType, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        \n",
    "        # Replace the final head with identity to get features\n",
    "        self.base_model.head.drop = nn.Identity()\n",
    "        self.base_model.head.fc = nn.Identity()\n",
    "        \n",
    "        # Create embedding for imaging type\n",
    "        self.imaging_type_embedding = nn.Embedding(num_imaging_types, embedding_dim)\n",
    "        \n",
    "        # New classifier that takes image features + imaging type embedding\n",
    "        self.classifier = nn.Linear(num_features + embedding_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x, imaging_type):\n",
    "        # Get image features from base model\n",
    "        image_features = self.base_model(x)\n",
    "        \n",
    "        # Get imaging type embedding\n",
    "        imaging_embedding = self.imaging_type_embedding(imaging_type)\n",
    "        \n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat([image_features, imaging_embedding], dim=1)\n",
    "        \n",
    "        # Final classification\n",
    "        output = self.classifier(combined_features)\n",
    "        return output\n",
    "\n",
    "def create_mvit_model(architecture='mvitv2_tiny', num_classes=4, num_imaging_types=2, pretrained=True):\n",
    "    \"\"\"Create MViT v2 (Multiscale Vision Transformer) model with imaging type support for multi-class classification\"\"\"\n",
    "    if architecture == 'mvitv2_tiny':\n",
    "        base_model = timm.create_model('mvitv2_tiny', pretrained=pretrained, num_classes=0)\n",
    "    elif architecture == 'mvitv2_small':\n",
    "        base_model = timm.create_model('mvitv2_small', pretrained=pretrained, num_classes=0)\n",
    "    elif architecture == 'mvitv2_base':\n",
    "        base_model = timm.create_model('mvitv2_base', pretrained=pretrained, num_classes=0)\n",
    "    else:\n",
    "        raise ValueError(\"Architecture must be 'mvitv2_tiny', 'mvitv2_small', or 'mvitv2_base'\")\n",
    "    \n",
    "    # Get number of features from the model\n",
    "    num_features = base_model.num_features\n",
    "    \n",
    "    # Wrap model with imaging type support\n",
    "    model = MViTWithImagingType(\n",
    "        base_model,\n",
    "        num_features=num_features,\n",
    "        num_classes=num_classes,\n",
    "        num_imaging_types=num_imaging_types\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96977e7",
   "metadata": {},
   "source": [
    "# Configure GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bee0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d19f30",
   "metadata": {},
   "source": [
    "# Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c99e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, model_name, save_path=None):\n",
    "    \"\"\"Plot confusion matrix with nice formatting\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title(f'Confusion Matrix - {model_name}', fontsize=16, pad=20)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curves(labels, probs, class_names, model_name, save_path=None):\n",
    "    \"\"\"Plot ROC curves for multi-class classification\"\"\"\n",
    "    # Binarize the labels\n",
    "    n_classes = len(class_names)\n",
    "    labels_bin = label_binarize(labels, classes=list(range(n_classes)))\n",
    "    probs_array = np.array(probs)\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(labels_bin[:, i], probs_array[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(labels_bin.ravel(), probs_array.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    colors = cycle(['blue', 'red', 'green', 'orange', 'purple'])\n",
    "    \n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'{class_names[i]} (AUC = {roc_auc[i]:.3f})')\n",
    "    \n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='deeppink', linestyle=':', linewidth=3,\n",
    "             label=f'Micro-average (AUC = {roc_auc[\"micro\"]:.3f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title(f'ROC Curves - {model_name}', fontsize=16, pad=20)\n",
    "    plt.legend(loc=\"lower right\", fontsize=10)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8c4bf",
   "metadata": {},
   "source": [
    "# Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names from label encoder\n",
    "class_names = list(label_encoder.classes_)\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Store results for all models\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e5403",
   "metadata": {},
   "source": [
    "## Train MViT v2 Tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Training MViT v2 Tiny with Imaging Type\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create model\n",
    "mvit_tiny = create_mvit_model(architecture='mvitv2_tiny', num_classes=4, num_imaging_types=2, pretrained=True)\n",
    "\n",
    "# Create trainer\n",
    "trainer_mvit_tiny = ModelTrainer(mvit_tiny, train_loader, val_loader, test_loader, device=device)\n",
    "\n",
    "# Train model\n",
    "trained_model_mvit_tiny = trainer_mvit_tiny.train_model(num_epochs=25, lr=0.001, save_best=True, model_name=\"MViT-V2-Tiny_with_ImagingType\")\n",
    "\n",
    "# Plot training history\n",
    "trainer_mvit_tiny.plot_training_history(save_path='mvit_v2_tiny_training_history.png')\n",
    "\n",
    "# Evaluate model\n",
    "results_mvit_tiny = trainer_mvit_tiny.evaluate_model(class_names=class_names)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(results_mvit_tiny['confusion_matrix'], class_names, 'MViT-V2-Tiny',\n",
    "                      save_path='mvit_v2_tiny_confusion_matrix.png')\n",
    "\n",
    "# Plot ROC curves\n",
    "roc_auc_mvit_tiny = plot_roc_curves(results_mvit_tiny['labels'], results_mvit_tiny['probabilities'], class_names, 'MViT-V2-Tiny',\n",
    "                                     save_path='mvit_v2_tiny_roc_curves.png')\n",
    "\n",
    "# Store results\n",
    "results_mvit_tiny['model_name'] = 'MViT-V2-Tiny_with_ImagingType'\n",
    "results_mvit_tiny['roc_auc'] = roc_auc_mvit_tiny\n",
    "all_results.append(results_mvit_tiny)\n",
    "\n",
    "print(\"\\nMViT v2 Tiny training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a5b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Training MViT v2 Base with Imaging Type\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create model\n",
    "mvit_base = create_mvit_model(architecture='mvitv2_base', num_classes=4, num_imaging_types=2, pretrained=True)\n",
    "\n",
    "# Create trainer\n",
    "trainer_mvit_base = ModelTrainer(mvit_base, train_loader, val_loader, test_loader, device=device)\n",
    "\n",
    "# Train model\n",
    "trained_model_mvit_base = trainer_mvit_base.train_model(num_epochs=25, lr=0.001, save_best=True, model_name=\"MViT-V2-Base_with_ImagingType\")\n",
    "\n",
    "# Plot training history\n",
    "trainer_mvit_base.plot_training_history(save_path='mvit_v2_base_training_history.png')\n",
    "\n",
    "# Evaluate model\n",
    "results_mvit_base = trainer_mvit_base.evaluate_model(class_names=class_names)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(results_mvit_base['confusion_matrix'], class_names, 'MViT-V2-Base',\n",
    "                      save_path='mvit_v2_base_confusion_matrix.png')\n",
    "\n",
    "# Plot ROC curves\n",
    "roc_auc_mvit_base = plot_roc_curves(results_mvit_base['labels'], results_mvit_base['probabilities'], class_names, 'MViT-V2-Base',\n",
    "                                     save_path='mvit_v2_base_roc_curves.png')\n",
    "\n",
    "# Store results\n",
    "results_mvit_base['model_name'] = 'MViT-V2-Base_with_ImagingType'\n",
    "results_mvit_base['roc_auc'] = roc_auc_mvit_base\n",
    "all_results.append(results_mvit_base)\n",
    "\n",
    "print(\"\\nMViT v2 Base training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dffdec6",
   "metadata": {},
   "source": [
    "## Train MViT v2 Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Training MViT v2 Small with Imaging Type\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create model\n",
    "mvit_small = create_mvit_model(architecture='mvitv2_small', num_classes=4, num_imaging_types=2, pretrained=True)\n",
    "\n",
    "# Create trainer\n",
    "trainer_mvit_small = ModelTrainer(mvit_small, train_loader, val_loader, test_loader, device=device)\n",
    "\n",
    "# Train model\n",
    "trained_model_mvit_small = trainer_mvit_small.train_model(num_epochs=25, lr=0.001, save_best=True, model_name=\"MViT-V2-Small_with_ImagingType\")\n",
    "\n",
    "# Plot training history\n",
    "trainer_mvit_small.plot_training_history(save_path='mvit_v2_small_training_history.png')\n",
    "\n",
    "# Evaluate model\n",
    "results_mvit_small = trainer_mvit_small.evaluate_model(class_names=class_names)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(results_mvit_small['confusion_matrix'], class_names, 'MViT-V2-Small',\n",
    "                      save_path='mvit_v2_small_confusion_matrix.png')\n",
    "\n",
    "# Plot ROC curves\n",
    "roc_auc_mvit_small = plot_roc_curves(results_mvit_small['labels'], results_mvit_small['probabilities'], class_names, 'MViT-V2-Small',\n",
    "                                     save_path='mvit_v2_small_roc_curves.png')\n",
    "\n",
    "# Store results\n",
    "results_mvit_small['model_name'] = 'MViT-V2-Small_with_ImagingType'\n",
    "results_mvit_small['roc_auc'] = roc_auc_mvit_small\n",
    "all_results.append(results_mvit_small)\n",
    "\n",
    "print(\"\\nMViT v2 Small training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf1316",
   "metadata": {},
   "source": [
    "## Train MViT v2 Small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc7ef6",
   "metadata": {},
   "source": [
    "# Save All Metrics to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for CSV\n",
    "metrics_data = []\n",
    "\n",
    "for result in all_results:\n",
    "    model_name = result['model_name']\n",
    "    report = result['classification_report']\n",
    "    \n",
    "    # Overall metrics\n",
    "    row = {\n",
    "        'Model': model_name,\n",
    "        'Overall_Accuracy': result['accuracy'],\n",
    "        'Overall_Loss': result['loss'],\n",
    "        'Macro_Avg_Precision': report['macro avg']['precision'],\n",
    "        'Macro_Avg_Recall': report['macro avg']['recall'],\n",
    "        'Macro_Avg_F1': report['macro avg']['f1-score'],\n",
    "        'Weighted_Avg_Precision': report['weighted avg']['precision'],\n",
    "        'Weighted_Avg_Recall': report['weighted avg']['recall'],\n",
    "        'Weighted_Avg_F1': report['weighted avg']['f1-score'],\n",
    "    }\n",
    "    \n",
    "    # Per-class metrics\n",
    "    for class_name in class_names:\n",
    "        row[f'{class_name}_Precision'] = report[class_name]['precision']\n",
    "        row[f'{class_name}_Recall'] = report[class_name]['recall']\n",
    "        row[f'{class_name}_F1'] = report[class_name]['f1-score']\n",
    "        row[f'{class_name}_Support'] = report[class_name]['support']\n",
    "    \n",
    "    # ROC-AUC scores\n",
    "    row['Macro_AUC'] = result['macro_auc']\n",
    "    row['Micro_AUC'] = result['micro_auc']\n",
    "    for class_name in class_names:\n",
    "        row[f'{class_name}_AUC'] = result['per_class_auc'][class_name]\n",
    "    \n",
    "    # Also store ROC-AUC from plot_roc_curves if available\n",
    "    if 'roc_auc' in result:\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            row[f'{class_name}_Plot_AUC'] = result['roc_auc'][i]\n",
    "        row['Micro_Avg_Plot_AUC'] = result['roc_auc']['micro']\n",
    "    \n",
    "    metrics_data.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'MViT_V2_metrics.csv'\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\nMetrics saved to: {csv_path}\")\n",
    "print(\"\\nMetrics Summary:\")\n",
    "print(metrics_df.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
