{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24158d78",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, f1_score, roc_auc_score\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d1068a",
   "metadata": {},
   "source": [
    "# Set Seeds for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0efb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Python random\n",
    "random.seed(SEED)\n",
    "\n",
    "# Numpy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)  # if using multi-GPU\n",
    "\n",
    "# PyTorch backend\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"Seeds set to {SEED} for reproducibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c5b06",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893324e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations - Minimal transformations without data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # RGB normalization\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # RGB normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c8686",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "class BladderTissueDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, label_encoder=None, imaging_type_encoder=None, fit_label_encoder=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (DataFrame): DataFrame with HLY (image paths), tissue type (labels), and imaging type columns.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            label_encoder (LabelEncoder, optional): Pre-fitted label encoder. If None, creates new one.\n",
    "            imaging_type_encoder (LabelEncoder, optional): Pre-fitted imaging type encoder.\n",
    "            fit_label_encoder (bool): Whether to fit the label encoder on this dataset's labels.\n",
    "        \"\"\"\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "        if label_encoder is None:\n",
    "            self.label_encoder = LabelEncoder()\n",
    "            if fit_label_encoder:\n",
    "                self.labels = self.label_encoder.fit_transform(self.data['tissue type'])\n",
    "            else:\n",
    "                raise ValueError(\"Must provide label_encoder or set fit_label_encoder=True\")\n",
    "        else:\n",
    "            self.label_encoder = label_encoder\n",
    "            self.labels = self.label_encoder.transform(self.data['tissue type'])\n",
    "        \n",
    "        # Handle imaging type encoding\n",
    "        if imaging_type_encoder is None:\n",
    "            self.imaging_type_encoder = LabelEncoder()\n",
    "            if fit_label_encoder:\n",
    "                self.imaging_types = self.imaging_type_encoder.fit_transform(self.data['imaging type'])\n",
    "            else:\n",
    "                raise ValueError(\"Must provide imaging_type_encoder or set fit_label_encoder=True\")\n",
    "        else:\n",
    "            self.imaging_type_encoder = imaging_type_encoder\n",
    "            self.imaging_types = self.imaging_type_encoder.transform(self.data['imaging type'])\n",
    "        \n",
    "        self.image_paths = self.data['HLY'].tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image: {img_path}\")\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        imaging_type = self.imaging_types[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.long), torch.tensor(imaging_type, dtype=torch.long)\n",
    "    \n",
    "    def get_label_encoder(self):\n",
    "        \"\"\"Return the label encoder for use with other datasets\"\"\"\n",
    "        return self.label_encoder\n",
    "    \n",
    "    def get_imaging_type_encoder(self):\n",
    "        \"\"\"Return the imaging type encoder for use with other datasets\"\"\"\n",
    "        return self.imaging_type_encoder\n",
    "    \n",
    "    def get_class_names(self):\n",
    "        \"\"\"Return the original class names\"\"\"\n",
    "        return self.label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffccb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets from DataFrames\n",
    "def create_datasets_from_dataframes(train_df, val_df, test_df):\n",
    "    \"\"\"\n",
    "    Create train, validation, and test datasets with proper label encoding\n",
    "    \"\"\"\n",
    "    # Create training dataset and fit label encoder\n",
    "    train_dataset = BladderTissueDataset(\n",
    "        dataframe=train_df, \n",
    "        transform=train_transform,\n",
    "        fit_label_encoder=True  \n",
    "    )\n",
    "    \n",
    "    # Get the fitted label encoder and imaging type encoder\n",
    "    le = train_dataset.get_label_encoder()\n",
    "    imaging_type_encoder = train_dataset.get_imaging_type_encoder()\n",
    "    \n",
    "    # Create validation dataset using the same label encoder\n",
    "    val_dataset = BladderTissueDataset(\n",
    "        dataframe=val_df,\n",
    "        transform=val_test_transform,\n",
    "        label_encoder=le,\n",
    "        imaging_type_encoder=imaging_type_encoder\n",
    "    )\n",
    "    \n",
    "    # Create test dataset using the same label encoder\n",
    "    test_dataset = BladderTissueDataset(\n",
    "        dataframe=test_df,\n",
    "        transform=val_test_transform,\n",
    "        label_encoder=le,\n",
    "        imaging_type_encoder=imaging_type_encoder\n",
    "    )\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset, le, imaging_type_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa395bf",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fab392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "def create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
    "    \"\"\"\n",
    "    Create dataloaders for training, validation, and testing\n",
    "    \"\"\"\n",
    "    # Worker seed for reproducibility\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "    \n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(42)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=seed_worker,    \n",
    "        generator=g    \n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        pin_memory=True,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/Applications/Projects/Bladder Research/Data/train.csv\")\n",
    "test_df = pd.read_csv(\"/Applications/Projects/Bladder Research/Data/test.csv\")\n",
    "valid_df = pd.read_csv(\"/Applications/Projects/Bladder Research/Data/valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36cd6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset, label_encoder, imaging_type_encoder = create_datasets_from_dataframes(\n",
    "    train_df, valid_df, test_df\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_dataset, val_dataset, test_dataset, \n",
    "    batch_size=32, \n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b11e0",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45616f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(train_loader, num_classes):\n",
    "    \"\"\"Compute class weights for handling imbalanced datasets\"\"\"\n",
    "    class_counts = Counter()\n",
    "\n",
    "    for _, labels, _ in train_loader:\n",
    "        class_counts.update(labels.numpy())\n",
    "\n",
    "    total_samples = sum(class_counts.values())\n",
    "\n",
    "    weights = []\n",
    "    for i in range(num_classes):\n",
    "        weights.append(total_samples / (num_classes * class_counts[i]))\n",
    "\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d12dc36",
   "metadata": {},
   "source": [
    "# Model Training Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        \n",
    "        # Training history\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "        \n",
    "    def train_model(self, num_epochs=25, lr=0.001, weight_decay=1e-4, save_best=True, model_name=\"model\"):\n",
    "        \"\"\"Train the model with early stopping and best model saving based on macro-F1\"\"\"\n",
    "        \n",
    "        # Loss function and optimizer\n",
    "        class_weights = compute_class_weights(self.train_loader, num_classes=len(self.train_loader.dataset.get_label_encoder().classes_))\n",
    "        class_weights = class_weights.to(self.device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "        \n",
    "        # Best model tracking\n",
    "        best_val_f1 = 0.0\n",
    "        best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "        patience = 5\n",
    "        patience_counter = 0\n",
    "        \n",
    "        print(f\"Starting training for {num_epochs} epochs...\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "            print('-' * 10)\n",
    "            \n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    self.model.train()\n",
    "                    dataloader = self.train_loader\n",
    "                else:\n",
    "                    self.model.eval()\n",
    "                    dataloader = self.val_loader\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                total_samples = 0\n",
    "                all_preds = []\n",
    "                all_labels = []\n",
    "                \n",
    "                # Progress bar\n",
    "                pbar = tqdm(dataloader, desc=f'{phase.capitalize()} ')\n",
    "                \n",
    "                for inputs, labels, imaging_types in pbar:\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "                    imaging_types = imaging_types.to(self.device)\n",
    "                    \n",
    "                    # Zero gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = self.model(inputs, imaging_types)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                        # Backward pass (only in training)\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    \n",
    "                    # Statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                    total_samples += inputs.size(0)\n",
    "                    \n",
    "                    # Store predictions and labels for F1 calculation\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    current_acc = running_corrects.double() / total_samples\n",
    "                    pbar.set_postfix({\n",
    "                        'Loss': f'{running_loss/total_samples:.4f}',\n",
    "                        'Acc': f'{current_acc:.4f}'\n",
    "                    })\n",
    "                \n",
    "                # Calculate epoch metrics\n",
    "                epoch_loss = running_loss / total_samples\n",
    "                epoch_acc = running_corrects.double() / total_samples\n",
    "                epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                \n",
    "                print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Macro-F1: {epoch_f1:.4f}')\n",
    "                \n",
    "                # Store metrics\n",
    "                if phase == 'train':\n",
    "                    self.train_losses.append(epoch_loss)\n",
    "                    self.train_accuracies.append(epoch_acc.cpu())\n",
    "                else:\n",
    "                    self.val_losses.append(epoch_loss)\n",
    "                    self.val_accuracies.append(epoch_acc.cpu())\n",
    "                \n",
    "                # Save best model based on validation macro-F1\n",
    "                if phase == 'val' and epoch_f1 > best_val_f1:\n",
    "                    best_val_f1 = epoch_f1\n",
    "                    best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "                    patience_counter = 0\n",
    "                    if save_best:\n",
    "                        torch.save(self.model.state_dict(), f'best_{model_name}.pth')\n",
    "                        print(f'âœ“ New best model saved with validation macro-F1: {best_val_f1:.4f}')\n",
    "                elif phase == 'val':\n",
    "                    patience_counter += 1\n",
    "            \n",
    "            # Learning rate scheduler step (after both train and val phases)\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "                break\n",
    "                \n",
    "            print()\n",
    "        \n",
    "        # Training complete\n",
    "        time_elapsed = time.time() - start_time\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best validation macro-F1: {best_val_f1:.4f}')\n",
    "        \n",
    "        # Load best model weights\n",
    "        self.model.load_state_dict(best_model_wts)\n",
    "        return self.model\n",
    "    \n",
    "    def evaluate_model(self, test_loader=None, class_names=['HGC', 'LGC', 'NST', 'NTL']):\n",
    "        \"\"\"Evaluate model on test set and return all metrics\"\"\"\n",
    "        if test_loader is None:\n",
    "            test_loader = self.test_loader\n",
    "            \n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        print(\"Evaluating on test set...\")\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels, imaging_types in tqdm(test_loader):\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                imaging_types = imaging_types.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs, imaging_types)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                # Store for detailed metrics\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        test_acc = 100 * correct / total\n",
    "        avg_test_loss = test_loss / total\n",
    "        \n",
    "        print(f'Test Accuracy: {test_acc:.2f}%')\n",
    "        print(f'Test Loss: {avg_test_loss:.4f}')\n",
    "        \n",
    "        # Detailed classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "        print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        print(f\"\\nConfusion Matrix:\")\n",
    "        print(cm)\n",
    "        \n",
    "        # Compute ROC-AUC scores\n",
    "        labels_bin = label_binarize(all_labels, classes=list(range(len(class_names))))\n",
    "        probs_array = np.array(all_probs)\n",
    "        \n",
    "        # Per-class ROC-AUC\n",
    "        per_class_auc = {}\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            try:\n",
    "                per_class_auc[class_name] = roc_auc_score(labels_bin[:, i], probs_array[:, i])\n",
    "            except:\n",
    "                per_class_auc[class_name] = 0.0\n",
    "        \n",
    "        # Macro ROC-AUC (average of per-class AUCs)\n",
    "        macro_auc = np.mean(list(per_class_auc.values()))\n",
    "        \n",
    "        # Micro ROC-AUC (using all predictions)\n",
    "        try:\n",
    "            micro_auc = roc_auc_score(labels_bin.ravel(), probs_array.ravel())\n",
    "        except:\n",
    "            micro_auc = 0.0\n",
    "        \n",
    "        print(f\"\\nROC-AUC Scores:\")\n",
    "        print(f\"Macro-average AUC: {macro_auc:.4f}\")\n",
    "        print(f\"Micro-average AUC: {micro_auc:.4f}\")\n",
    "        for class_name, auc_score in per_class_auc.items():\n",
    "            print(f\"{class_name} AUC: {auc_score:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'accuracy': test_acc,\n",
    "            'loss': avg_test_loss,\n",
    "            'predictions': all_preds,\n",
    "            'labels': all_labels,\n",
    "            'probabilities': all_probs,\n",
    "            'confusion_matrix': cm,\n",
    "            'classification_report': report,\n",
    "            'per_class_auc': per_class_auc,\n",
    "            'macro_auc': macro_auc,\n",
    "            'micro_auc': micro_auc\n",
    "        }\n",
    "    \n",
    "    def plot_training_history(self, save_path=None):\n",
    "        \"\"\"Plot training and validation metrics\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Plot losses\n",
    "        ax1.plot(self.train_losses, label='Train Loss', marker='o')\n",
    "        ax1.plot(self.val_losses, label='Validation Loss', marker='s')\n",
    "        ax1.set_title('Model Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Plot accuracies\n",
    "        ax2.plot(self.train_accuracies, label='Train Accuracy', marker='o')\n",
    "        ax2.plot(self.val_accuracies, label='Validation Accuracy', marker='s')\n",
    "        ax2.set_title('Model Accuracy')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "        ax2.set_xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071fa984",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a329e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetWithImagingType(nn.Module):\n",
    "    def __init__(self, base_model, num_features, num_classes=4, num_imaging_types=2, embedding_dim=16):\n",
    "        super(ResNetWithImagingType, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        \n",
    "        # Remove the final fc layer\n",
    "        self.base_model.fc = nn.Identity()\n",
    "        \n",
    "        # Imaging type embedding\n",
    "        self.imaging_type_embedding = nn.Embedding(num_imaging_types, embedding_dim)\n",
    "        \n",
    "        # New classifier that takes both image features and imaging type\n",
    "        self.classifier = nn.Linear(num_features + embedding_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x, imaging_type):\n",
    "        # Get image features\n",
    "        image_features = self.base_model(x)\n",
    "        \n",
    "        # Get imaging type embedding\n",
    "        imaging_embedding = self.imaging_type_embedding(imaging_type)\n",
    "        \n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat([image_features, imaging_embedding], dim=1)\n",
    "        \n",
    "        # Final classification\n",
    "        output = self.classifier(combined_features)\n",
    "        return output\n",
    "\n",
    "def create_resnet_model(model_type='resnet50', num_classes=4, num_imaging_types=2, pretrained=True):\n",
    "    \"\"\"\n",
    "    Create ResNet model with imaging type input for bladder tissue classification\n",
    "    \n",
    "    Args:\n",
    "        model_type (str): ResNet architecture - 'resnet50' or 'resnet101'\n",
    "        num_classes (int): Number of output classes\n",
    "        num_imaging_types (int): Number of imaging types\n",
    "        pretrained (bool): Whether to use pretrained weights\n",
    "    \n",
    "    Returns:\n",
    "        model: ResNet model with imaging type support\n",
    "    \"\"\"\n",
    "    if model_type == 'resnet50':\n",
    "        base_model = models.resnet50(pretrained=pretrained)\n",
    "    elif model_type == 'resnet101':\n",
    "        base_model = models.resnet101(pretrained=pretrained)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "    \n",
    "    # Get num_features before modifying the model\n",
    "    num_features = base_model.fc.in_features\n",
    "    \n",
    "    # Wrap with imaging type support\n",
    "    model = ResNetWithImagingType(base_model, num_features=num_features, num_classes=num_classes, num_imaging_types=num_imaging_types)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96977e7",
   "metadata": {},
   "source": [
    "# Configure GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bee0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d19f30",
   "metadata": {},
   "source": [
    "# Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c99e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, model_name, save_path=None):\n",
    "    \"\"\"Plot confusion matrix with nice formatting\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title(f'Confusion Matrix - {model_name}', fontsize=16, pad=20)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curves(labels, probs, class_names, model_name, save_path=None):\n",
    "    \"\"\"Plot ROC curves for multi-class classification\"\"\"\n",
    "    # Binarize the labels\n",
    "    n_classes = len(class_names)\n",
    "    labels_bin = label_binarize(labels, classes=list(range(n_classes)))\n",
    "    probs_array = np.array(probs)\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(labels_bin[:, i], probs_array[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(labels_bin.ravel(), probs_array.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    colors = cycle(['blue', 'red', 'green', 'orange', 'purple'])\n",
    "    \n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'{class_names[i]} (AUC = {roc_auc[i]:.3f})')\n",
    "    \n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='deeppink', linestyle=':', linewidth=3,\n",
    "             label=f'Micro-average (AUC = {roc_auc[\"micro\"]:.3f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title(f'ROC Curves - {model_name}', fontsize=16, pad=20)\n",
    "    plt.legend(loc=\"lower right\", fontsize=10)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8c4bf",
   "metadata": {},
   "source": [
    "# Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names from label encoder\n",
    "class_names = list(label_encoder.classes_)\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Store results for all models\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e5403",
   "metadata": {},
   "source": [
    "## Train ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Training ResNet-50 with Imaging Type\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create model\n",
    "resnet50 = create_resnet_model(model_type='resnet50', num_classes=4, num_imaging_types=2, pretrained=True)\n",
    "\n",
    "# Create trainer\n",
    "trainer_50 = ModelTrainer(resnet50, train_loader, val_loader, test_loader, device=device)\n",
    "\n",
    "# Train model\n",
    "trained_model_50 = trainer_50.train_model(num_epochs=25, lr=0.001, save_best=True, model_name=\"resnet50_with_ImagingType\")\n",
    "\n",
    "# Plot training history\n",
    "trainer_50.plot_training_history(save_path='resnet50_training_history.png')\n",
    "\n",
    "# Evaluate model\n",
    "results_50 = trainer_50.evaluate_model(class_names=class_names)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(results_50['confusion_matrix'], class_names, 'ResNet-50',\n",
    "                      save_path='resnet50_confusion_matrix.png')\n",
    "\n",
    "# Plot ROC curves\n",
    "roc_auc_50 = plot_roc_curves(results_50['labels'], results_50['probabilities'], class_names, 'ResNet-50',\n",
    "                              save_path='resnet50_roc_curves.png')\n",
    "# Store results\n",
    "results_50['model_name'] = 'ResNet-50'\n",
    "results_50['roc_auc'] = roc_auc_50\n",
    "all_results.append(results_50)\n",
    "\n",
    "print(\"\\nResNet-50 training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d2d05",
   "metadata": {},
   "source": [
    "## Train ResNet-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d2d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Training ResNet-101 with Imaging Type\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create model\n",
    "resnet101 = create_resnet_model(model_type='resnet101', num_classes=4, num_imaging_types=2, pretrained=True)\n",
    "\n",
    "# Create trainer\n",
    "trainer_101 = ModelTrainer(resnet101, train_loader, val_loader, test_loader, device=device)\n",
    "\n",
    "# Train model\n",
    "trained_model_101 = trainer_101.train_model(num_epochs=25, lr=0.001, save_best=True, model_name=\"resnet101_with_ImagingType\")\n",
    "\n",
    "# Plot training history\n",
    "trainer_101.plot_training_history(save_path='resnet101_training_history.png')\n",
    "\n",
    "# Evaluate model\n",
    "results_101 = trainer_101.evaluate_model(class_names=class_names)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(results_101['confusion_matrix'], class_names, 'ResNet-101',\n",
    "                      save_path='resnet101_confusion_matrix.png')\n",
    "\n",
    "# Plot ROC curves\n",
    "roc_auc_101 = plot_roc_curves(results_101['labels'], results_101['probabilities'], class_names, 'ResNet-101',\n",
    "                               save_path='resnet101_roc_curves.png')\n",
    "# Store results\n",
    "results_101['model_name'] = 'ResNet-101'\n",
    "results_101['roc_auc'] = roc_auc_101\n",
    "all_results.append(results_101)\n",
    "\n",
    "print(\"\\nResNet-101 training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc7ef6",
   "metadata": {},
   "source": [
    "# Save All Metrics to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for CSV\n",
    "metrics_data = []\n",
    "\n",
    "for result in all_results:\n",
    "    model_name = result['model_name']\n",
    "    report = result['classification_report']\n",
    "    \n",
    "    # Overall metrics\n",
    "    row = {\n",
    "        'Model': model_name,\n",
    "        'Overall_Accuracy': result['accuracy'],\n",
    "        'Overall_Loss': result['loss'],\n",
    "        'Macro_Avg_Precision': report['macro avg']['precision'],\n",
    "        'Macro_Avg_Recall': report['macro avg']['recall'],\n",
    "        'Macro_Avg_F1': report['macro avg']['f1-score'],\n",
    "        'Weighted_Avg_Precision': report['weighted avg']['precision'],\n",
    "        'Weighted_Avg_Recall': report['weighted avg']['recall'],\n",
    "        'Weighted_Avg_F1': report['weighted avg']['f1-score'],\n",
    "    }\n",
    "    \n",
    "    # Per-class metrics\n",
    "    for class_name in class_names:\n",
    "        row[f'{class_name}_Precision'] = report[class_name]['precision']\n",
    "        row[f'{class_name}_Recall'] = report[class_name]['recall']\n",
    "        row[f'{class_name}_F1'] = report[class_name]['f1-score']\n",
    "        row[f'{class_name}_Support'] = report[class_name]['support']\n",
    "    \n",
    "    # ROC-AUC scores\n",
    "    row['Macro_AUC'] = result['macro_auc']\n",
    "    row['Micro_AUC'] = result['micro_auc']\n",
    "    for class_name in class_names:\n",
    "        row[f'{class_name}_AUC'] = result['per_class_auc'][class_name]\n",
    "    \n",
    "    # Also store ROC-AUC from plot_roc_curves if available\n",
    "    if 'roc_auc' in result:\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            row[f'{class_name}_Plot_AUC'] = result['roc_auc'][i]\n",
    "        row['Micro_Avg_Plot_AUC'] = result['roc_auc']['micro']\n",
    "    \n",
    "    metrics_data.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'models_with_no_augmentation_and_imaging_type.csv'\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\nMetrics saved to: {csv_path}\")\n",
    "print(\"\\nMetrics Summary:\")\n",
    "print(metrics_df.to_string())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
