{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24158d78",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, f1_score, roc_auc_score\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d1068a",
   "metadata": {},
   "source": [
    "# Set Seeds for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0efb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Python random\n",
    "random.seed(SEED)\n",
    "\n",
    "# Numpy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)  # if using multi-GPU\n",
    "\n",
    "# PyTorch backend\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"Seeds set to {SEED} for reproducibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c5b06",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893324e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet normalization constants\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Training transformations with data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(\n",
    "        size=224,\n",
    "        scale=(0.9, 1.0),\n",
    "        ratio=(0.95, 1.05)\n",
    "    ),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.1,\n",
    "        contrast=0.1,\n",
    "        saturation=0.05,\n",
    "        hue=0.02\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=IMAGENET_MEAN,\n",
    "        std=IMAGENET_STD\n",
    "    )\n",
    "])\n",
    "\n",
    "# Validation and test transformations without augmentation\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=IMAGENET_MEAN,\n",
    "        std=IMAGENET_STD\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c8686",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "class BladderTissueDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, label_encoder=None, fit_label_encoder=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (DataFrame): DataFrame with HLY (image paths) and tissue type (labels) columns.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            label_encoder (LabelEncoder, optional): Pre-fitted label encoder. If None, creates new one.\n",
    "            fit_label_encoder (bool): Whether to fit the label encoder on this dataset's labels.\n",
    "        \"\"\"\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "        if label_encoder is None:\n",
    "            self.label_encoder = LabelEncoder()\n",
    "            if fit_label_encoder:\n",
    "                self.labels = self.label_encoder.fit_transform(self.data['tissue type'])\n",
    "            else:\n",
    "                raise ValueError(\"Must provide label_encoder or set fit_label_encoder=True\")\n",
    "        else:\n",
    "            self.label_encoder = label_encoder\n",
    "            self.labels = self.label_encoder.transform(self.data['tissue type'])\n",
    "        \n",
    "        self.image_paths = self.data['HLY'].tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image: {img_path}\")\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "    def get_label_encoder(self):\n",
    "        \"\"\"Return the label encoder for use with other datasets\"\"\"\n",
    "        return self.label_encoder\n",
    "    \n",
    "    def get_class_names(self):\n",
    "        \"\"\"Return the original class names\"\"\"\n",
    "        return self.label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffccb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets from DataFrames\n",
    "def create_datasets_from_dataframes(train_df, val_df, test_df):\n",
    "    \"\"\"\n",
    "    Create train, validation, and test datasets with proper label encoding\n",
    "    \"\"\"\n",
    "    # Create training dataset and fit label encoder\n",
    "    train_dataset = BladderTissueDataset(\n",
    "        dataframe=train_df, \n",
    "        transform=train_transform,\n",
    "        fit_label_encoder=True\n",
    "    )\n",
    "    \n",
    "    # Get the fitted label encoder\n",
    "    le = train_dataset.get_label_encoder()\n",
    "    \n",
    "    # Create validation dataset using the same label encoder\n",
    "    val_dataset = BladderTissueDataset(\n",
    "        dataframe=val_df,\n",
    "        transform=val_test_transform,\n",
    "        label_encoder=le\n",
    "    )\n",
    "    \n",
    "    # Create test dataset using the same label encoder\n",
    "    test_dataset = BladderTissueDataset(\n",
    "        dataframe=test_df,\n",
    "        transform=val_test_transform,\n",
    "        label_encoder=le\n",
    "    )\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset, le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa395bf",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fab392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "def create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
    "    \"\"\"\n",
    "    Create dataloaders for training, validation, and testing\n",
    "    \"\"\"\n",
    "    # Worker seed for reproducibility\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "    \n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(42)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=seed_worker,    \n",
    "        generator=g    \n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        pin_memory=True,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/ebt-dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/ebt-dataset/test.csv\")\n",
    "valid_df = pd.read_csv(\"/kaggle/input/ebt-dataset/valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853f4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze imaging type distribution across datasets and tissue types\n",
    "print(\"=\" * 60)\n",
    "print(\"IMAGING TYPE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for df_name, df in [(\"Train\", train_df), (\"Validation\", valid_df), (\"Test\", test_df)]:\n",
    "    print(f\"\\n{df_name} Set:\")\n",
    "    print(f\"  Total samples: {len(df)}\")\n",
    "    print(f\"\\n  Imaging Type Distribution:\")\n",
    "    print(df['imaging type'].value_counts())\n",
    "    print(f\"\\n  Imaging Type by Tissue Type:\")\n",
    "    print(df.groupby(['tissue type', 'imaging type']).size().unstack(fill_value=0))\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43179b1",
   "metadata": {},
   "source": [
    "# Analyze Imaging Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36cd6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset, label_encoder = create_datasets_from_dataframes(\n",
    "    train_df, valid_df, test_df\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_dataset, val_dataset, test_dataset, \n",
    "    batch_size=32, \n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# Print encoding information\n",
    "print(f\"Tissue Types: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b11e0",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45616f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(train_loader, num_classes):\n",
    "    \"\"\"Compute class weights for handling imbalanced datasets\"\"\"\n",
    "    class_counts = Counter()\n",
    "\n",
    "    for _, labels in train_loader:\n",
    "        class_counts.update(labels.numpy())\n",
    "\n",
    "    total_samples = sum(class_counts.values())\n",
    "\n",
    "    weights = []\n",
    "    for i in range(num_classes):\n",
    "        weights.append(total_samples / (num_classes * class_counts[i]))\n",
    "\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d12dc36",
   "metadata": {},
   "source": [
    "# Model Training Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        \n",
    "        # Training history\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "        \n",
    "    def train_model(self, num_epochs=25, lr=0.001, weight_decay=1e-4, save_best=True, model_name=\"model\"):\n",
    "        \"\"\"Train the model with early stopping and best model saving based on macro-F1\"\"\"\n",
    "        \n",
    "        # Loss function and optimizer\n",
    "        class_weights = compute_class_weights(self.train_loader, num_classes=len(self.train_loader.dataset.get_label_encoder().classes_))\n",
    "        class_weights = class_weights.to(self.device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "        \n",
    "        # Best model tracking\n",
    "        best_val_f1 = 0.0\n",
    "        best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "        patience = 5\n",
    "        patience_counter = 0\n",
    "        \n",
    "        print(f\"Starting training for {num_epochs} epochs...\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "            print('-' * 10)\n",
    "            \n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    self.model.train()\n",
    "                    dataloader = self.train_loader\n",
    "                else:\n",
    "                    self.model.eval()\n",
    "                    dataloader = self.val_loader\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                total_samples = 0\n",
    "                all_preds = []\n",
    "                all_labels = []\n",
    "                \n",
    "                # Progress bar\n",
    "                pbar = tqdm(dataloader, desc=f'{phase.capitalize()} ')\n",
    "                \n",
    "                for inputs, labels in pbar:\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "                    \n",
    "                    # Zero gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = self.model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                        # Backward pass (only in training)\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    \n",
    "                    # Statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                    total_samples += inputs.size(0)\n",
    "                    \n",
    "                    # Store predictions and labels for F1 calculation\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    current_acc = running_corrects.double() / total_samples\n",
    "                    pbar.set_postfix({\n",
    "                        'Loss': f'{running_loss/total_samples:.4f}',\n",
    "                        'Acc': f'{current_acc:.4f}'\n",
    "                    })\n",
    "                \n",
    "                # Calculate epoch metrics\n",
    "                epoch_loss = running_loss / total_samples\n",
    "                epoch_acc = running_corrects.double() / total_samples\n",
    "                epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                \n",
    "                print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Macro-F1: {epoch_f1:.4f}')\n",
    "                \n",
    "                # Store metrics\n",
    "                if phase == 'train':\n",
    "                    self.train_losses.append(epoch_loss)\n",
    "                    self.train_accuracies.append(epoch_acc.cpu())\n",
    "                else:\n",
    "                    self.val_losses.append(epoch_loss)\n",
    "                    self.val_accuracies.append(epoch_acc.cpu())\n",
    "                \n",
    "                # Save best model based on validation macro-F1\n",
    "                if phase == 'val' and epoch_f1 > best_val_f1:\n",
    "                    best_val_f1 = epoch_f1\n",
    "                    best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "                    patience_counter = 0\n",
    "                    if save_best:\n",
    "                        torch.save(self.model.state_dict(), f'best_{model_name}.pth')\n",
    "                        print(f'âœ“ New best model saved with validation macro-F1: {best_val_f1:.4f}')\n",
    "                elif phase == 'val':\n",
    "                    patience_counter += 1\n",
    "            \n",
    "            # Learning rate scheduler step (after both train and val phases)\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "                break\n",
    "                \n",
    "            print()\n",
    "        \n",
    "        # Training complete\n",
    "        time_elapsed = time.time() - start_time\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best validation macro-F1: {best_val_f1:.4f}')\n",
    "        \n",
    "        # Load best model weights\n",
    "        self.model.load_state_dict(best_model_wts)\n",
    "        return self.model\n",
    "    \n",
    "    def evaluate_model(self, test_loader=None, class_names=['HGC', 'LGC', 'NST', 'NTL']):\n",
    "        \"\"\"Evaluate model on test set and return all metrics\"\"\"\n",
    "        if test_loader is None:\n",
    "            test_loader = self.test_loader\n",
    "            \n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        print(\"Evaluating on test set...\")\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(test_loader):\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                # Store for detailed metrics\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        test_acc = 100 * correct / total\n",
    "        avg_test_loss = test_loss / total\n",
    "        \n",
    "        print(f'Test Accuracy: {test_acc:.2f}%')\n",
    "        print(f'Test Loss: {avg_test_loss:.4f}')\n",
    "        \n",
    "        # Detailed classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "        print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        print(f\"\\nConfusion Matrix:\")\n",
    "        print(cm)\n",
    "        \n",
    "        # Compute ROC-AUC scores\n",
    "        labels_bin = label_binarize(all_labels, classes=list(range(len(class_names))))\n",
    "        probs_array = np.array(all_probs)\n",
    "        \n",
    "        # Per-class ROC-AUC\n",
    "        per_class_auc = {}\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            try:\n",
    "                per_class_auc[class_name] = roc_auc_score(labels_bin[:, i], probs_array[:, i])\n",
    "            except:\n",
    "                per_class_auc[class_name] = 0.0\n",
    "        \n",
    "        # Macro ROC-AUC (average of per-class AUCs)\n",
    "        macro_auc = np.mean(list(per_class_auc.values()))\n",
    "        \n",
    "        # Micro ROC-AUC (using all predictions)\n",
    "        try:\n",
    "            micro_auc = roc_auc_score(labels_bin.ravel(), probs_array.ravel())\n",
    "        except:\n",
    "            micro_auc = 0.0\n",
    "        \n",
    "        print(f\"\\nROC-AUC Scores:\")\n",
    "        print(f\"Macro-average AUC: {macro_auc:.4f}\")\n",
    "        print(f\"Micro-average AUC: {micro_auc:.4f}\")\n",
    "        for class_name, auc_score in per_class_auc.items():\n",
    "            print(f\"{class_name} AUC: {auc_score:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'accuracy': test_acc,\n",
    "            'loss': avg_test_loss,\n",
    "            'predictions': all_preds,\n",
    "            'labels': all_labels,\n",
    "            'probabilities': all_probs,\n",
    "            'confusion_matrix': cm,\n",
    "            'classification_report': report,\n",
    "            'per_class_auc': per_class_auc,\n",
    "            'macro_auc': macro_auc,\n",
    "            'micro_auc': micro_auc\n",
    "        }\n",
    "    \n",
    "    def plot_training_history(self, save_path=None):\n",
    "        \"\"\"Plot training and validation metrics\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Plot losses\n",
    "        ax1.plot(self.train_losses, label='Train Loss', marker='o')\n",
    "        ax1.plot(self.val_losses, label='Validation Loss', marker='s')\n",
    "        ax1.set_title('Model Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Plot accuracies\n",
    "        ax2.plot(self.train_accuracies, label='Train Accuracy', marker='o')\n",
    "        ax2.plot(self.val_accuracies, label='Validation Accuracy', marker='s')\n",
    "        ax2.set_title('Model Accuracy')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071fa984",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a329e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regnet_y_400mf(num_classes=4, pretrained=True):\n",
    "    \"\"\"Create RegNet-Y-400MF model for bladder tissue classification\"\"\"\n",
    "    model = models.regnet_y_400mf(weights='DEFAULT' if pretrained else None)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def create_regnet_y_800mf(num_classes=4, pretrained=True):\n",
    "    \"\"\"Create RegNet-Y-800MF model for bladder tissue classification\"\"\"\n",
    "    model = models.regnet_y_800mf(weights='DEFAULT' if pretrained else None)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def create_regnet_y_1_6gf(num_classes=4, pretrained=True):\n",
    "    \"\"\"Create RegNet-Y-1.6GF model for bladder tissue classification\"\"\"\n",
    "    model = models.regnet_y_1_6gf(weights='DEFAULT' if pretrained else None)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96977e7",
   "metadata": {},
   "source": [
    "# Configure GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bee0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d19f30",
   "metadata": {},
   "source": [
    "# Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c99e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, model_name, save_path=None):\n",
    "    \"\"\"Plot confusion matrix with nice formatting\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title(f'Confusion Matrix - {model_name}', fontsize=16, pad=20)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curves(labels, probs, class_names, model_name, save_path=None):\n",
    "    \"\"\"Plot ROC curves for multi-class classification\"\"\"\n",
    "    # Binarize the labels\n",
    "    n_classes = len(class_names)\n",
    "    labels_bin = label_binarize(labels, classes=list(range(n_classes)))\n",
    "    probs_array = np.array(probs)\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(labels_bin[:, i], probs_array[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(labels_bin.ravel(), probs_array.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    colors = cycle(['blue', 'red', 'green', 'orange', 'purple'])\n",
    "    \n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'{class_names[i]} (AUC = {roc_auc[i]:.3f})')\n",
    "    \n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='deeppink', linestyle=':', linewidth=3,\n",
    "             label=f'Micro-average (AUC = {roc_auc[\"micro\"]:.3f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title(f'ROC Curves - {model_name}', fontsize=16, pad=20)\n",
    "    plt.legend(loc=\"lower right\", fontsize=10)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8c4bf",
   "metadata": {},
   "source": [
    "# Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names from label encoder\n",
    "class_names = list(label_encoder.classes_)\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Store results for all models\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e5403",
   "metadata": {},
   "source": [
    "## Train RegNet-Y-400MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Training RegNet-Y-400MF\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create RegNet-Y-400MF model\n",
    "regnet_400mf = create_regnet_y_400mf(\n",
    "    num_classes=4,\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer_400mf = ModelTrainer(regnet_400mf, train_loader, val_loader, test_loader, device=device)\n",
    "\n",
    "# Train model\n",
    "trained_model_400mf = trainer_400mf.train_model(num_epochs=25, lr=0.001, save_best=True, model_name=\"RegNet-Y-400MF\")\n",
    "\n",
    "# Plot training history\n",
    "trainer_400mf.plot_training_history(save_path='regnet_y_400mf_training_history.png')\n",
    "\n",
    "# Evaluate model\n",
    "results_400mf = trainer_400mf.evaluate_model(class_names=class_names)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(results_400mf['confusion_matrix'], class_names, 'RegNet-Y-400MF',\n",
    "                      save_path='regnet_y_400mf_confusion_matrix.png')\n",
    "# Plot ROC curves\n",
    "roc_auc_400mf = plot_roc_curves(results_400mf['labels'], results_400mf['probabilities'], class_names, 'RegNet-Y-400MF',\n",
    "                              save_path='regnet_y_400mf_roc_curves.png')\n",
    "# Store results\n",
    "results_400mf['model_name'] = 'RegNet-Y-400MF'\n",
    "results_400mf['roc_auc'] = roc_auc_400mf\n",
    "all_results.append(results_400mf)\n",
    "\n",
    "print(\"\\nRegNet-Y-400MF training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d51b8d8",
   "metadata": {},
   "source": [
    "## Train RegNet-Y-800MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a667ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Training RegNet-Y-800MF\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create RegNet-Y-800MF model\n",
    "regnet_800mf = create_regnet_y_800mf(\n",
    "    num_classes=4,\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer_800mf = ModelTrainer(regnet_800mf, train_loader, val_loader, test_loader, device=device)\n",
    "\n",
    "# Train model\n",
    "trained_model_800mf = trainer_800mf.train_model(num_epochs=25, lr=0.001, save_best=True, model_name=\"RegNet-Y-800MF\")\n",
    "\n",
    "# Plot training history\n",
    "trainer_800mf.plot_training_history(save_path='regnet_y_800mf_training_history.png')\n",
    "\n",
    "# Evaluate model\n",
    "results_800mf = trainer_800mf.evaluate_model(class_names=class_names)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(results_800mf['confusion_matrix'], class_names, 'RegNet-Y-800MF',\n",
    "                      save_path='regnet_y_800mf_confusion_matrix.png')\n",
    "# Plot ROC curves\n",
    "roc_auc_800mf = plot_roc_curves(results_800mf['labels'], results_800mf['probabilities'], class_names, 'RegNet-Y-800MF',\n",
    "                              save_path='regnet_y_800mf_roc_curves.png')\n",
    "# Store results\n",
    "results_800mf['model_name'] = 'RegNet-Y-800MF'\n",
    "results_800mf['roc_auc'] = roc_auc_800mf\n",
    "all_results.append(results_800mf)\n",
    "\n",
    "print(\"\\nRegNet-Y-800MF training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d142dcda",
   "metadata": {},
   "source": [
    "## Train RegNet-Y-1.6GF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4545b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Training RegNet-Y-1.6GF\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create RegNet-Y-1.6GF model\n",
    "regnet_1_6gf = create_regnet_y_1_6gf(\n",
    "    num_classes=4,\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer_1_6gf = ModelTrainer(regnet_1_6gf, train_loader, val_loader, test_loader, device=device)\n",
    "\n",
    "# Train model\n",
    "trained_model_1_6gf = trainer_1_6gf.train_model(num_epochs=25, lr=0.001, save_best=True, model_name=\"RegNet-Y-1.6GF\")\n",
    "\n",
    "# Plot training history\n",
    "trainer_1_6gf.plot_training_history(save_path='regnet_y_1_6gf_training_history.png')\n",
    "\n",
    "# Evaluate model\n",
    "results_1_6gf = trainer_1_6gf.evaluate_model(class_names=class_names)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(results_1_6gf['confusion_matrix'], class_names, 'RegNet-Y-1.6GF',\n",
    "                      save_path='regnet_y_1_6gf_confusion_matrix.png')\n",
    "# Plot ROC curves\n",
    "roc_auc_1_6gf = plot_roc_curves(results_1_6gf['labels'], results_1_6gf['probabilities'], class_names, 'RegNet-Y-1.6GF',\n",
    "                              save_path='regnet_y_1_6gf_roc_curves.png')\n",
    "# Store results\n",
    "results_1_6gf['model_name'] = 'RegNet-Y-1.6GF'\n",
    "results_1_6gf['roc_auc'] = roc_auc_1_6gf\n",
    "all_results.append(results_1_6gf)\n",
    "\n",
    "print(\"\\nRegNet-Y-1.6GF training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc7ef6",
   "metadata": {},
   "source": [
    "# Save All Metrics to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for CSV\n",
    "metrics_data = []\n",
    "\n",
    "for result in all_results:\n",
    "    model_name = result['model_name']\n",
    "    report = result['classification_report']\n",
    "    \n",
    "    # Overall metrics\n",
    "    row = {\n",
    "        'Model': model_name,\n",
    "        'Overall_Accuracy': result['accuracy'],\n",
    "        'Overall_Loss': result['loss'],\n",
    "        'Macro_Avg_Precision': report['macro avg']['precision'],\n",
    "        'Macro_Avg_Recall': report['macro avg']['recall'],\n",
    "        'Macro_Avg_F1': report['macro avg']['f1-score'],\n",
    "        'Weighted_Avg_Precision': report['weighted avg']['precision'],\n",
    "        'Weighted_Avg_Recall': report['weighted avg']['recall'],\n",
    "        'Weighted_Avg_F1': report['weighted avg']['f1-score'],\n",
    "    }\n",
    "    \n",
    "    # Per-class metrics\n",
    "    for class_name in class_names:\n",
    "        row[f'{class_name}_Precision'] = report[class_name]['precision']\n",
    "        row[f'{class_name}_Recall'] = report[class_name]['recall']\n",
    "        row[f'{class_name}_F1'] = report[class_name]['f1-score']\n",
    "        row[f'{class_name}_Support'] = report[class_name]['support']\n",
    "    \n",
    "    # ROC-AUC scores\n",
    "    row['Macro_AUC'] = result['macro_auc']\n",
    "    row['Micro_AUC'] = result['micro_auc']\n",
    "    for class_name in class_names:\n",
    "        row[f'{class_name}_AUC'] = result['per_class_auc'][class_name]\n",
    "    \n",
    "    # Also store ROC-AUC from plot_roc_curves if available\n",
    "    if 'roc_auc' in result:\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            row[f'{class_name}_Plot_AUC'] = result['roc_auc'][i]\n",
    "        row['Micro_Avg_Plot_AUC'] = result['roc_auc']['micro']\n",
    "    \n",
    "    metrics_data.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'RegNet_metrics.csv'\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\nMetrics saved to: {csv_path}\")\n",
    "print(\"\\nMetrics Summary:\")\n",
    "print(metrics_df.to_string())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
